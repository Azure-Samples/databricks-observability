{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9f952466-b625-4382-a854-5b1e552d6868",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[1]: <pyspark.sql.streaming.query.StreamingQuery at 0x7f41e4ab31f0>"
     ]
    }
   ],
   "source": [
    "# Run a dummy streaming query so that MBeans for streaming metrics are created\n",
    "# (provided spark.sql.streaming.metricsEnabled=true)\n",
    "(spark\n",
    "    .readStream\n",
    "    .format(\"rate\")\n",
    "    .load()\n",
    "    .writeStream\n",
    "    .foreach(print)\n",
    "    .start())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8b5f1457-08b0-47e8-b219-d563dd18e1ab",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sh\n",
    "# Write a script to collect all JMX metrics available for all Java processes\n",
    "# into a JSON snippet compatible with the \"jmxMetrics\" field of the applicationinsights.json file\n",
    "# (Application Insights Java agent configuration file).\n",
    "# See https://learn.microsoft.com/azure/azure-monitor/app/java-jmx-metrics-configuration\n",
    "\n",
    "rm -rf /dbfs/metrics/\n",
    "mkdir -p /dbfs/metrics/result\n",
    "\n",
    "cat <<EOF >/dbfs/metrics/dump-jmx-metrics.sh\n",
    "\n",
    "test -e jmxterm-1.0.4-uber.jar || wget -q https://github.com/jiaqi/jmxterm/releases/download/v1.0.4/jmxterm-1.0.4-uber.jar\n",
    "for pid in \\$(ps -e | grep java | cut -f3 -d ' '); do\n",
    "\n",
    "  echo \"PID: \\$pid\"\n",
    "\n",
    "  # Output available domains to notebook\n",
    "  echo \"open \\$pid\" > jmxterm-commands.txt\n",
    "  echo \"domains\" >> jmxterm-commands.txt\n",
    "  java -jar jmxterm-1.0.4-uber.jar -i jmxterm-commands.txt\n",
    "\n",
    "  # List MBean names in desired domains\n",
    "  echo \"open \\$pid\" > jmxterm-commands.txt\n",
    "  for domain in \"java.lang\" \"metrics\"; do\n",
    "    echo \"beans -d \\$domain\" >> jmxterm-commands.txt\n",
    "  done\n",
    "  java -jar jmxterm-1.0.4-uber.jar -i jmxterm-commands.txt > jmxterm-output.txt\n",
    "\n",
    "  # Skip java processes that are not related to Spark\n",
    "  grep --quiet name=spark jmxterm-output.txt || continue\n",
    "\n",
    "  # Generate jmxterm commands file to list attributes for each MBean\n",
    "  echo \"open \\$pid\" > jmxterm-commands-detailed.txt\n",
    "  python -c 'import sys, re; [sys.stdout.write(f\"bean {line}\\ninfo\\n\") for line in sys.stdin]' < jmxterm-output.txt >> jmxterm-commands-detailed.txt\n",
    "\n",
    "  # Spaces in MBean names must be escaped in jmxterm command\n",
    "  # see https://github.com/jiaqi/jmxterm/issues/41\n",
    "  # This sed command replaces each space starting with the second occurrence\n",
    "  sed -i 's/ /\\\\\\\\ /2g' jmxterm-commands-detailed.txt\n",
    "  \n",
    "  # Output MBeans detailed information to output file\n",
    "  java -jar jmxterm-1.0.4-uber.jar -i jmxterm-commands-detailed.txt > /dbfs/metrics/result/\\$1\\$SPARK_LOCAL_IP-\\$pid.txt 2>&1\n",
    "done\n",
    "EOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9807d3fe-e5f4-477b-8b23-dbac807161be",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PID: 477\nWelcome to JMX terminal. Type \"help\" for available commands.\n#Connection to 477 is opened\n#following domains are available\nJMImplementation\ncom.sun.management\njava.lang\njava.nio\njava.util.logging\njdk.management.jfr\norg.apache.logging.log4j2\nWelcome to JMX terminal. Type \"help\" for available commands.\n#Connection to 477 is opened\n#domain = java.lang:\n#IllegalArgumentException: Domain metrics doesn't exist, check your spelling\nPID: 577\nWelcome to JMX terminal. Type \"help\" for available commands.\n#Connection to 577 is opened\n#following domains are available\nJMImplementation\ncom.sun.management\njava.lang\njava.nio\njava.util.logging\njdk.management.jfr\norg.apache.logging.log4j2\nWelcome to JMX terminal. Type \"help\" for available commands.\n#Connection to 577 is opened\n#domain = java.lang:\n#IllegalArgumentException: Domain metrics doesn't exist, check your spelling\nPID: 808\nWelcome to JMX terminal. Type \"help\" for available commands.\n#Connection to 808 is opened\n#following domains are available\nJMImplementation\ncom.sun.management\njava.lang\njava.nio\njava.util.logging\njdk.management.jfr\nmetrics\norg.apache.commons.pool2\norg.apache.logging.log4j2\nWelcome to JMX terminal. Type \"help\" for available commands.\n#Connection to 808 is opened\n#domain = java.lang:\n#domain = metrics:\n"
     ]
    }
   ],
   "source": [
    "%sh \n",
    "# Run the script for the driver\n",
    "bash /dbfs/metrics/dump-jmx-metrics.sh driver-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8dde58ef-6f99-4984-a59c-6249cf5549d0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">import scala.concurrent.duration._\n",
       "res: scala.collection.Map[String,scala.util.Try[String]] =\n",
       "Map(0 -&gt; Success(PID: 638\n",
       "JMImplementation\n",
       "com.sun.management\n",
       "java.lang\n",
       "java.nio\n",
       "java.util.logging\n",
       "jdk.management.jfr\n",
       "org.apache.logging.log4j2\n",
       "PID: 823\n",
       "JMImplementation\n",
       "com.sun.management\n",
       "java.lang\n",
       "java.nio\n",
       "java.util.logging\n",
       "jdk.management.jfr\n",
       "metrics\n",
       "org.apache.logging.log4j2\n",
       "))\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">import scala.concurrent.duration._\nres: scala.collection.Map[String,scala.util.Try[String]] =\nMap(0 -&gt; Success(PID: 638\nJMImplementation\ncom.sun.management\njava.lang\njava.nio\njava.util.logging\njdk.management.jfr\norg.apache.logging.log4j2\nPID: 823\nJMImplementation\ncom.sun.management\njava.lang\njava.nio\njava.util.logging\njdk.management.jfr\nmetrics\norg.apache.logging.log4j2\n))\n</div>",
       "datasetInfos": [],
       "metadata": {
        "isDbfsCommandResult": false
       },
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%scala\n",
    "// Run the script for each executor\n",
    "\n",
    "import scala.concurrent.duration._\n",
    "\n",
    "var res=sc.runOnEachExecutor[String]({ () =>\n",
    "  import sys.process._\n",
    "  var cmd_Result=Seq(\"bash\", \"-c\", \"/dbfs/metrics/dump-jmx-metrics.sh\").!!\n",
    "  cmd_Result\n",
    "  }, 100.seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3eff8e28-0192-443c-99e6-1f2711aabc6d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[0m\u001B[01;32m10.139.64.4-823.txt\u001B[0m*  \u001B[01;32mdriver-10.139.64.5-808.txt\u001B[0m*\r\n"
     ]
    }
   ],
   "source": [
    "%ls /dbfs/metrics/result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "222ad545-ce29-4d95-a14a-0eb650a296be",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Parse the detailed output of jmxterm (text file with mbean names and attributes)\n",
    "# into the JSON format of \"jmxMetrics\" field of the applicationinsights.json file.\n",
    "\n",
    "import os, re, json\n",
    "\n",
    "# Define the directory path where the jmxterm output files are located.\n",
    "# Output JSON files are also written in this location.\n",
    "directory = '/dbfs/metrics/result'\n",
    "\n",
    "# Read each .txt file in the directory.\n",
    "for filename in os.listdir(directory):\n",
    "    if not filename.endswith('.txt'):\n",
    "        continue\n",
    "\n",
    "    filepath = os.path.join(directory, filename)\n",
    "    \n",
    "    # read the file\n",
    "    with open(filepath, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    # read all mbean/attribute combinations into a results list\n",
    "    results = []\n",
    "    in_attributes_section = False\n",
    "    for line in lines:\n",
    "        if line.startswith('#'):\n",
    "            in_attributes_section = line.startswith('# attributes')\n",
    "            if line.startswith('#mbean = '):\n",
    "                mbean_name = line.rstrip().removeprefix('#mbean = ')\n",
    "                mbean_name_short = mbean_name.split(',')[0]\n",
    "        elif in_attributes_section:\n",
    "            match = re.search(r'  - (\\S*).*,', line) \n",
    "            result_string = match.group(1)\n",
    "            results.append({\"name\": mbean_name_short, \"objectName\": mbean_name, \"attribute\": result_string})\n",
    "\n",
    "    # filter and process results\n",
    "    filtered_results = []\n",
    "\n",
    "    for result in results:\n",
    "        others = len([1 for r in results if r[\"objectName\"] == result[\"objectName\"]])\n",
    "        if others > 1:\n",
    "            # Add the attribute name to the metric name, except when there is only one attribute\n",
    "            # (or the other attribute is \"Value\" and this attribute is \"Number\", see exclusion rule below)\n",
    "            if not(result[\"attribute\"] == \"Number\" and not any(r[\"objectName\"] == result[\"objectName\"] and r[\"attribute\"] != \"Value\" and r[\"attribute\"] != \"Number\" for r in results)):\n",
    "                result[\"name\"] = f'{result[\"name\"]}.{result[\"attribute\"]}' \n",
    "\n",
    "    for result in results:\n",
    "        # skip deprecated metrics (redundant with other metrics)\n",
    "        if 'blacklist' in result[\"objectName\"].lower():\n",
    "            continue\n",
    "\n",
    "        # Exclude weird object names from nested/anonymous classes\n",
    "        if '$' in result[\"objectName\"]:\n",
    "            continue\n",
    "\n",
    "        # Use JMX MBean Object Name Patterns for executor metric names which are dependent of the executor ID\n",
    "        result[\"objectName\"] = re.sub(r'^metrics:name=spark\\.\\d+\\.', 'metrics:name=spark.*.', result[\"objectName\"])\n",
    "\n",
    "        # Streaming metrics: make independent of job ID, simplify prefix\n",
    "        m = r'^metrics:name=spark\\.driver\\.spark\\.streaming\\.[0-9a-f]{8}-[0-9a-f]{4}-[1-5][0-9a-f]{3}-[89ab][0-9a-f]{3}-[0-9a-f]{12}\\.'\n",
    "        result[\"objectName\"] = re.sub(m, 'metrics:name=spark.driver.spark.streaming.*.', result[\"objectName\"])\n",
    "        result[\"name\"] = re.sub(m, 'metrics:name=spark.streaming.', result[\"name\"])\n",
    "\n",
    "        # Make Spark metric names shorter and independent of the executor ID\n",
    "        result[\"name\"] = re.sub(r'^metrics:name=spark\\.\\d+\\.', 'spark.worker.', result[\"name\"])\n",
    "        result[\"name\"] = re.sub(r'^metrics:name=spark\\.', 'spark.', result[\"name\"])\n",
    "\n",
    "        # Exclude \"Value\" attributes when a \"Number\" attribute exists, since their values are then identical\n",
    "        if result[\"attribute\"] == \"Value\" and any(r[\"objectName\"] == result[\"objectName\"] and r[\"attribute\"] == \"Number\" for r in results):\n",
    "            continue\n",
    "\n",
    "        filtered_results.append(result)\n",
    "    \n",
    "    # sort and output results\n",
    "    dedup_results = [dict(t) for t in {tuple(d.items()) for d in filtered_results}]\n",
    "    sorted_results = sorted(dedup_results, key=lambda x: (x['name'], x['objectName'], x['attribute']))\n",
    "        \n",
    "    with open(filepath + '.json', 'w') as f:\n",
    "        json.dump(sorted_results, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "86d4c9ef-40bd-4b99-b920-32c87c4b2d0c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/dbfs/metrics/result/driver-10.139.64.5-808.txt.json:        \"name\": \"spark.streaming.processingRate-total\",\n/dbfs/metrics/result/driver-10.139.64.5-808.txt.json:        \"objectName\": \"metrics:name=spark.driver.spark.streaming.*.processingRate-total,type=gauges\",\n/dbfs/metrics/result/10.139.64.4-823.txt.json:        \"name\": \"spark.worker.executor.threadpool.activeTasks\",\n/dbfs/metrics/result/10.139.64.4-823.txt.json:        \"objectName\": \"metrics:name=spark.*.executor.threadpool.activeTasks,type=gauges\",\n/dbfs/metrics/result/10.139.64.4-823.txt.json:        \"name\": \"java.lang:type=OperatingSystem.ProcessCpuLoad\",\n/dbfs/metrics/result/10.139.64.4-823.txt.json:        \"attribute\": \"ProcessCpuLoad\"\n/dbfs/metrics/result/driver-10.139.64.5-808.txt.json:        \"name\": \"java.lang:type=OperatingSystem.ProcessCpuLoad\",\n/dbfs/metrics/result/driver-10.139.64.5-808.txt.json:        \"attribute\": \"ProcessCpuLoad\"\n/dbfs/metrics/result/10.139.64.4-823.txt.json:        \"name\": \"spark.worker.ExecutorMetrics.OnHeapStorageMemory\",\n/dbfs/metrics/result/10.139.64.4-823.txt.json:        \"objectName\": \"metrics:name=spark.*.ExecutorMetrics.OnHeapStorageMemory,type=gauges\",\n/dbfs/metrics/result/driver-10.139.64.5-808.txt.json:        \"name\": \"spark.driver.ExecutorMetrics.OnHeapStorageMemory\",\n/dbfs/metrics/result/driver-10.139.64.5-808.txt.json:        \"objectName\": \"metrics:name=spark.driver.ExecutorMetrics.OnHeapStorageMemory,type=gauges\",\n/dbfs/metrics/result/10.139.64.4-823.txt.json:        \"name\": \"java.lang:name=Code Cache.CollectionUsageThresholdExceeded\",\n/dbfs/metrics/result/10.139.64.4-823.txt.json:        \"attribute\": \"CollectionUsageThresholdExceeded\"\n/dbfs/metrics/result/10.139.64.4-823.txt.json:        \"name\": \"java.lang:name=Compressed Class Space.CollectionUsageThresholdExceeded\",\n/dbfs/metrics/result/10.139.64.4-823.txt.json:        \"attribute\": \"CollectionUsageThresholdExceeded\"\n/dbfs/metrics/result/10.139.64.4-823.txt.json:        \"name\": \"java.lang:name=Metaspace.CollectionUsageThresholdExceeded\",\n/dbfs/metrics/result/10.139.64.4-823.txt.json:        \"attribute\": \"CollectionUsageThresholdExceeded\"\n/dbfs/metrics/result/10.139.64.4-823.txt.json:        \"name\": \"java.lang:name=PS Eden Space.CollectionUsageThresholdExceeded\",\n/dbfs/metrics/result/10.139.64.4-823.txt.json:        \"attribute\": \"CollectionUsageThresholdExceeded\"\n/dbfs/metrics/result/10.139.64.4-823.txt.json:        \"name\": \"java.lang:name=PS Old Gen.CollectionUsageThresholdExceeded\",\n/dbfs/metrics/result/10.139.64.4-823.txt.json:        \"attribute\": \"CollectionUsageThresholdExceeded\"\n/dbfs/metrics/result/10.139.64.4-823.txt.json:        \"name\": \"java.lang:name=PS Survivor Space.CollectionUsageThresholdExceeded\",\n/dbfs/metrics/result/10.139.64.4-823.txt.json:        \"attribute\": \"CollectionUsageThresholdExceeded\"\n/dbfs/metrics/result/driver-10.139.64.5-808.txt.json:        \"name\": \"java.lang:name=Code Cache.CollectionUsageThresholdExceeded\",\n/dbfs/metrics/result/driver-10.139.64.5-808.txt.json:        \"attribute\": \"CollectionUsageThresholdExceeded\"\n/dbfs/metrics/result/driver-10.139.64.5-808.txt.json:        \"name\": \"java.lang:name=Compressed Class Space.CollectionUsageThresholdExceeded\",\n/dbfs/metrics/result/driver-10.139.64.5-808.txt.json:        \"attribute\": \"CollectionUsageThresholdExceeded\"\n/dbfs/metrics/result/driver-10.139.64.5-808.txt.json:        \"name\": \"java.lang:name=Metaspace.CollectionUsageThresholdExceeded\",\n/dbfs/metrics/result/driver-10.139.64.5-808.txt.json:        \"attribute\": \"CollectionUsageThresholdExceeded\"\n/dbfs/metrics/result/driver-10.139.64.5-808.txt.json:        \"name\": \"java.lang:name=PS Eden Space.CollectionUsageThresholdExceeded\",\n/dbfs/metrics/result/driver-10.139.64.5-808.txt.json:        \"attribute\": \"CollectionUsageThresholdExceeded\"\n/dbfs/metrics/result/driver-10.139.64.5-808.txt.json:        \"name\": \"java.lang:name=PS Old Gen.CollectionUsageThresholdExceeded\",\n/dbfs/metrics/result/driver-10.139.64.5-808.txt.json:        \"attribute\": \"CollectionUsageThresholdExceeded\"\n/dbfs/metrics/result/driver-10.139.64.5-808.txt.json:        \"name\": \"java.lang:name=PS Survivor Space.CollectionUsageThresholdExceeded\",\n/dbfs/metrics/result/driver-10.139.64.5-808.txt.json:        \"attribute\": \"CollectionUsageThresholdExceeded\"\n"
     ]
    }
   ],
   "source": [
    "%sh\n",
    "# Show some sample lines\n",
    "grep processingRate /dbfs/metrics/result/*.json\n",
    "grep activeTask /dbfs/metrics/result/*.json\n",
    "grep ProcessCpuLoad /dbfs/metrics/result/*.json\n",
    "grep OnHeapStorageMemory /dbfs/metrics/result/*.json\n",
    "grep CollectionUsageThresholdExceeded /dbfs/metrics/result/*.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "61e8c45e-f2cf-48c2-8da4-c91327b450b7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: dbfs/metrics/result/10.139.64.4-823.txt (deflated 94%)\n  adding: dbfs/metrics/result/10.139.64.4-823.txt.json (deflated 94%)\n  adding: dbfs/metrics/result/driver-10.139.64.5-808.txt (deflated 95%)\n  adding: dbfs/metrics/result/driver-10.139.64.5-808.txt.json (deflated 96%)\n"
     ]
    }
   ],
   "source": [
    "%sh \n",
    "zip /tmp/metrics.zip /dbfs/metrics/result/*\n",
    "mkdir -p /dbfs/FileStore\n",
    "mv /tmp/metrics.zip /dbfs/FileStore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cbfd3fef-04dd-4f13-a7ba-daabd6d9fd8e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "After running the notebook, download the template JSON files at [metrics.zip](/files/metrics.zip)."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 3601562193455676,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "dump-jmx",
   "notebookOrigID": 3601562193455669,
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
